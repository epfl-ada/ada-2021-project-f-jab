{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oA_fe4oxWT6p"
   },
   "source": [
    "# Mouting the Google Drive\n",
    "\n",
    "It is possible to mount your Google Drive to Colab if you need additional storage or if you need to use files from it. To do that run (click on play button or use keyboard shortcut 'Command/Ctrl+Enter') the following code cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CEcIlRwfWY4C",
    "outputId": "349b1fcc-cf88-4096-9932-1532bee845c1"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-d5df0069828e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/content/drive'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0vOPobprkF2h"
   },
   "source": [
    "For feasibility (and runtime), we decided to focus on only some top movies from each year (also as we would assume that they provide the most quotes related to them). So, we first take the dataset about movies and ratings from IMDb to derive the top 10 movies for each year, and afterwards filter the quotes related to these movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "4JIAKg0RZjU2"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import bz2\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wo-mHDSg9Nzd"
   },
   "source": [
    "We first load the dataset and then parse the year it was published into an integer, as it turned out initially that there were some years at strings and some as numerical values, which messed up our groupby. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P8XxvEoMZpIZ",
    "outputId": "f8fc8132-2d08-46ca-dcca-00e64b62450b"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './drive/MyDrive/imdb/IMDb movies.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-d39c12fea468>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmovie_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./drive/MyDrive/imdb/IMDb movies.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 811\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1038\u001b[0m             )\n\u001b[0;32m   1039\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1040\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\io\\parsers\\base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \"\"\"\n\u001b[1;32m--> 222\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    700\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './drive/MyDrive/imdb/IMDb movies.csv'"
     ]
    }
   ],
   "source": [
    "movie_df = pd.read_csv(\"./drive/MyDrive/imdb/IMDb movies.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 666
    },
    "id": "8fwQgRbCdrrX",
    "outputId": "152ca5ed-ed1c-49c1-e627-6f056f97191f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imdb_title_id</th>\n",
       "      <th>title</th>\n",
       "      <th>original_title</th>\n",
       "      <th>year</th>\n",
       "      <th>date_published</th>\n",
       "      <th>genre</th>\n",
       "      <th>duration</th>\n",
       "      <th>country</th>\n",
       "      <th>language</th>\n",
       "      <th>director</th>\n",
       "      <th>writer</th>\n",
       "      <th>production_company</th>\n",
       "      <th>actors</th>\n",
       "      <th>description</th>\n",
       "      <th>avg_vote</th>\n",
       "      <th>votes</th>\n",
       "      <th>budget</th>\n",
       "      <th>usa_gross_income</th>\n",
       "      <th>worlwide_gross_income</th>\n",
       "      <th>metascore</th>\n",
       "      <th>reviews_from_users</th>\n",
       "      <th>reviews_from_critics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt0000009</td>\n",
       "      <td>Miss Jerry</td>\n",
       "      <td>Miss Jerry</td>\n",
       "      <td>1894.0</td>\n",
       "      <td>1894-10-09</td>\n",
       "      <td>Romance</td>\n",
       "      <td>45</td>\n",
       "      <td>USA</td>\n",
       "      <td>None</td>\n",
       "      <td>Alexander Black</td>\n",
       "      <td>Alexander Black</td>\n",
       "      <td>Alexander Black Photoplays</td>\n",
       "      <td>Blanche Bayliss, William Courtenay, Chauncey D...</td>\n",
       "      <td>The adventures of a female reporter in the 1890s.</td>\n",
       "      <td>5.9</td>\n",
       "      <td>154</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt0000574</td>\n",
       "      <td>The Story of the Kelly Gang</td>\n",
       "      <td>The Story of the Kelly Gang</td>\n",
       "      <td>1906.0</td>\n",
       "      <td>1906-12-26</td>\n",
       "      <td>Biography, Crime, Drama</td>\n",
       "      <td>70</td>\n",
       "      <td>Australia</td>\n",
       "      <td>None</td>\n",
       "      <td>Charles Tait</td>\n",
       "      <td>Charles Tait</td>\n",
       "      <td>J. and N. Tait</td>\n",
       "      <td>Elizabeth Tait, John Tait, Norman Campbell, Be...</td>\n",
       "      <td>True story of notorious Australian outlaw Ned ...</td>\n",
       "      <td>6.1</td>\n",
       "      <td>589</td>\n",
       "      <td>$ 2250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt0001892</td>\n",
       "      <td>Den sorte drøm</td>\n",
       "      <td>Den sorte drøm</td>\n",
       "      <td>1911.0</td>\n",
       "      <td>1911-08-19</td>\n",
       "      <td>Drama</td>\n",
       "      <td>53</td>\n",
       "      <td>Germany, Denmark</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Urban Gad</td>\n",
       "      <td>Urban Gad, Gebhard Schätzler-Perasini</td>\n",
       "      <td>Fotorama</td>\n",
       "      <td>Asta Nielsen, Valdemar Psilander, Gunnar Helse...</td>\n",
       "      <td>Two men of high rank are both wooing the beaut...</td>\n",
       "      <td>5.8</td>\n",
       "      <td>188</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt0002101</td>\n",
       "      <td>Cleopatra</td>\n",
       "      <td>Cleopatra</td>\n",
       "      <td>1912.0</td>\n",
       "      <td>1912-11-13</td>\n",
       "      <td>Drama, History</td>\n",
       "      <td>100</td>\n",
       "      <td>USA</td>\n",
       "      <td>English</td>\n",
       "      <td>Charles L. Gaskill</td>\n",
       "      <td>Victorien Sardou</td>\n",
       "      <td>Helen Gardner Picture Players</td>\n",
       "      <td>Helen Gardner, Pearl Sindelar, Miss Fielding, ...</td>\n",
       "      <td>The fabled queen of Egypt's affair with Roman ...</td>\n",
       "      <td>5.2</td>\n",
       "      <td>446</td>\n",
       "      <td>$ 45000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt0002130</td>\n",
       "      <td>L'Inferno</td>\n",
       "      <td>L'Inferno</td>\n",
       "      <td>1911.0</td>\n",
       "      <td>1911-03-06</td>\n",
       "      <td>Adventure, Drama, Fantasy</td>\n",
       "      <td>68</td>\n",
       "      <td>Italy</td>\n",
       "      <td>Italian</td>\n",
       "      <td>Francesco Bertolini, Adolfo Padovan</td>\n",
       "      <td>Dante Alighieri</td>\n",
       "      <td>Milano Film</td>\n",
       "      <td>Salvatore Papa, Arturo Pirovano, Giuseppe de L...</td>\n",
       "      <td>Loosely adapted from Dante's Divine Comedy and...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2237</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  imdb_title_id  ... reviews_from_critics\n",
       "0     tt0000009  ...                  2.0\n",
       "1     tt0000574  ...                  7.0\n",
       "2     tt0001892  ...                  2.0\n",
       "3     tt0002101  ...                  3.0\n",
       "4     tt0002130  ...                 14.0\n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_df['year'] = pd.to_numeric(movie_df['year'], errors='coerce') # coerce: give NaN when parsing did not work\n",
    "movie_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Pp2djXfCa9-C"
   },
   "outputs": [],
   "source": [
    "movie_counts = movie_df.groupby('year')['imdb_title_id'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bflr3pWzcQWg",
    "outputId": "5cb07a7a-bbba-418c-d7ca-3f3c14cc961d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16331"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_counts[2015] + movie_counts[2016] + movie_counts[2017] + movie_counts[2018] + movie_counts[2019] + movie_counts[2020]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lh0x9um2-MIC"
   },
   "source": [
    "To define a \"top-movie\" for a year, we consider the worldwide gross income of it (we consider this as a sort of \"democratic vote\" on whether or not the movie is good enough to be watched). Therefore, we first drop NaN values in the 'worlwide_gross_income'[sic!] column, and parse it by filtering out all movies whose income was not given in US-Dollars (It turns out that the worldwide successful movies all had their income in US-Dollars, and we also did not find it feasible to convert local currencies with some currency converters to US Dollar, as most of they were mostly locally succesful productions). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hGo_0eu_i3_6",
    "outputId": "2b013fc7-788e-4c01-ec20-a095a56d50cc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31016, 22)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_df_nona = movie_df.dropna(subset=['worlwide_gross_income'])\n",
    "movie_df_nona.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "xswRMZzmjxCC"
   },
   "outputs": [],
   "source": [
    "movie_counts_nona = movie_df_nona.groupby('year')['imdb_title_id'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D55PVRNgkcJn",
    "outputId": "d6a46d80-1477-407b-945a-5e37fd652587"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8331"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_counts_nona[2015] + movie_counts_nona[2016] + movie_counts_nona[2017] + movie_counts_nona[2018] + movie_counts_nona[2019] + movie_counts_nona[2020]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f6_GY2HPk1aq",
    "outputId": "181a54cd-52b3-4a09-820a-4023747bdab5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "movie_df_nona['worldwide_gross_income'] = movie_df_nona[movie_df_nona['worlwide_gross_income'].astype(str).str.startswith('$')]['worlwide_gross_income'].str.replace('\\$ ', '').astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 734
    },
    "id": "CszZycFapVSx",
    "outputId": "db612fff-2dc6-407f-9803-9e4760631499"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imdb_title_id</th>\n",
       "      <th>title</th>\n",
       "      <th>original_title</th>\n",
       "      <th>year</th>\n",
       "      <th>date_published</th>\n",
       "      <th>genre</th>\n",
       "      <th>duration</th>\n",
       "      <th>country</th>\n",
       "      <th>language</th>\n",
       "      <th>director</th>\n",
       "      <th>writer</th>\n",
       "      <th>production_company</th>\n",
       "      <th>actors</th>\n",
       "      <th>description</th>\n",
       "      <th>avg_vote</th>\n",
       "      <th>votes</th>\n",
       "      <th>budget</th>\n",
       "      <th>usa_gross_income</th>\n",
       "      <th>worlwide_gross_income</th>\n",
       "      <th>metascore</th>\n",
       "      <th>reviews_from_users</th>\n",
       "      <th>reviews_from_critics</th>\n",
       "      <th>worldwide_gross_income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58734</th>\n",
       "      <td>tt1502397</td>\n",
       "      <td>Bad Boys for Life</td>\n",
       "      <td>Bad Boys for Life</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>2020-02-20</td>\n",
       "      <td>Action, Comedy, Crime</td>\n",
       "      <td>124</td>\n",
       "      <td>USA, Mexico</td>\n",
       "      <td>English, Spanish</td>\n",
       "      <td>Adil El Arbi, Bilall Fallah</td>\n",
       "      <td>Peter Craig, Joe Carnahan</td>\n",
       "      <td>Columbia Pictures</td>\n",
       "      <td>Will Smith, Martin Lawrence, Vanessa Hudgens, ...</td>\n",
       "      <td>Miami detectives Mike Lowrey and Marcus Burnet...</td>\n",
       "      <td>6.6</td>\n",
       "      <td>111557</td>\n",
       "      <td>$ 90000000</td>\n",
       "      <td>$ 204417855</td>\n",
       "      <td>$ 424617855</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1072.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>424617855.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72664</th>\n",
       "      <td>tt3794354</td>\n",
       "      <td>Sonic - Il film</td>\n",
       "      <td>Sonic the Hedgehog</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>2020-02-13</td>\n",
       "      <td>Action, Adventure, Comedy</td>\n",
       "      <td>99</td>\n",
       "      <td>USA, Japan, Canada</td>\n",
       "      <td>English, French</td>\n",
       "      <td>Jeff Fowler</td>\n",
       "      <td>Pat Casey, Josh Miller</td>\n",
       "      <td>Paramount Pictures</td>\n",
       "      <td>Ben Schwartz, James Marsden, Jim Carrey, Tika ...</td>\n",
       "      <td>After discovering a small, blue, fast hedgehog...</td>\n",
       "      <td>6.5</td>\n",
       "      <td>74639</td>\n",
       "      <td>$ 85000000</td>\n",
       "      <td>$ 146066470</td>\n",
       "      <td>$ 306766470</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1018.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>306766470.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82258</th>\n",
       "      <td>tt7294150</td>\n",
       "      <td>Ba Bai</td>\n",
       "      <td>Ba Bai</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>2020-08-21</td>\n",
       "      <td>War</td>\n",
       "      <td>147</td>\n",
       "      <td>China</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>Hu Guan</td>\n",
       "      <td>Hu Guan, Rui Ge</td>\n",
       "      <td>Beijing Diqi Yinxiang Entertainment</td>\n",
       "      <td>Zhi-zhong Huang, Zhang Junyi, Hao Ou, Wu Jiang...</td>\n",
       "      <td>From the acclaimed filmmaker behind Mr. Six co...</td>\n",
       "      <td>7.2</td>\n",
       "      <td>387</td>\n",
       "      <td>$ 80000000</td>\n",
       "      <td>$ 111552</td>\n",
       "      <td>$ 277207347</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>277207347.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80994</th>\n",
       "      <td>tt6673612</td>\n",
       "      <td>Dolittle</td>\n",
       "      <td>Dolittle</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>2020-01-30</td>\n",
       "      <td>Adventure, Comedy, Family</td>\n",
       "      <td>101</td>\n",
       "      <td>USA, China, UK, Japan</td>\n",
       "      <td>English, French</td>\n",
       "      <td>Stephen Gaghan</td>\n",
       "      <td>Stephen Gaghan, Dan Gregor</td>\n",
       "      <td>Universal Pictures</td>\n",
       "      <td>Robert Downey Jr., Antonio Banderas, Michael S...</td>\n",
       "      <td>A physician who can talk to animals embarks on...</td>\n",
       "      <td>5.6</td>\n",
       "      <td>39245</td>\n",
       "      <td>$ 175000000</td>\n",
       "      <td>$ 77047065</td>\n",
       "      <td>$ 245891166</td>\n",
       "      <td>26.0</td>\n",
       "      <td>680.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>245891166.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83078</th>\n",
       "      <td>tt7713068</td>\n",
       "      <td>Birds of Prey e la fantasmagorica rinascita di...</td>\n",
       "      <td>Birds of Prey: And the Fantabulous Emancipatio...</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>2020-02-06</td>\n",
       "      <td>Action, Adventure, Crime</td>\n",
       "      <td>109</td>\n",
       "      <td>USA</td>\n",
       "      <td>English, Chinese</td>\n",
       "      <td>Cathy Yan</td>\n",
       "      <td>Christina Hodson, Paul Dini</td>\n",
       "      <td>Clubhouse Pictures (II)</td>\n",
       "      <td>Margot Robbie, Rosie Perez, Mary Elizabeth Win...</td>\n",
       "      <td>After splitting with the Joker, Harley Quinn j...</td>\n",
       "      <td>6.1</td>\n",
       "      <td>137373</td>\n",
       "      <td>$ 84500000</td>\n",
       "      <td>$ 84158461</td>\n",
       "      <td>$ 201858461</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2222.0</td>\n",
       "      <td>372.0</td>\n",
       "      <td>201858461.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      imdb_title_id  ... worldwide_gross_income\n",
       "58734     tt1502397  ...            424617855.0\n",
       "72664     tt3794354  ...            306766470.0\n",
       "82258     tt7294150  ...            277207347.0\n",
       "80994     tt6673612  ...            245891166.0\n",
       "83078     tt7713068  ...            201858461.0\n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_df_nona[movie_df_nona['year'] == 2020].sort_values(by='worldwide_gross_income', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CM_l_n53AroY"
   },
   "source": [
    "Out of these successful movies, we now create a dictionary to get the successful movies per year, having the year as a key and the list of movie titles as value. We save this file both as pickle and (for convenience) also directly in this notebook as a hardcoded dict, given it is rather small. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "BfUT5jcRqvNy"
   },
   "outputs": [],
   "source": [
    "def get_most_succesful_movies_per_year(df, year, number=10):\n",
    "  return df[df['year'] == year].sort_values(by='worldwide_gross_income', ascending=False).head(number)['original_title'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "Wa6-wntArx-R"
   },
   "outputs": [],
   "source": [
    "most_successful_movies = dict()\n",
    "for year in range(2015,2021):\n",
    "  most_successful_movies[year] = get_most_succesful_movies_per_year(movie_df_nona, year)\n",
    "most_successful_movies[2015]\n",
    "with open('./drive/MyDrive/most_successful_movies.pickle', 'wb') as f:  \n",
    "  pickle.dump(most_successful_movies, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "bAMjRMxAtNwT"
   },
   "outputs": [],
   "source": [
    "most_successful_movies = {2015: ['Star Wars: Episode VII - The Force Awakens',\n",
    "  'Jurassic World',\n",
    "  'Fast & Furious 7',\n",
    "  'Avengers: Age of Ultron',\n",
    "  'Minions',\n",
    "  'Spectre',\n",
    "  'Inside Out',\n",
    "  'Mission: Impossible - Rogue Nation',\n",
    "  'The Hunger Games: Mockingjay - Part 2',\n",
    "  'The Martian'],\n",
    " 2016: ['Captain America: Civil War',\n",
    "  'Rogue One',\n",
    "  'Finding Dory',\n",
    "  'Zootopia',\n",
    "  'The Jungle Book',\n",
    "  'The Secret Life of Pets',\n",
    "  'Batman v Superman: Dawn of Justice',\n",
    "  'Fantastic Beasts and Where to Find Them',\n",
    "  'Deadpool',\n",
    "  'Suicide Squad'],\n",
    " 2017: ['Star Wars: Episode VIII - The Last Jedi',\n",
    "  'Beauty and the Beast',\n",
    "  'The Fate of the Furious',\n",
    "  'Despicable Me 3',\n",
    "  'Jumanji: Welcome to the Jungle',\n",
    "  'Spider-Man: Homecoming',\n",
    "  'Zhan lang II',\n",
    "  'Guardians of the Galaxy Vol. 2',\n",
    "  'Thor: Ragnarok',\n",
    "  'Wonder Woman'],\n",
    " 2018: ['Avengers: Infinity War',\n",
    "  'Black Panther',\n",
    "  'Jurassic World: Fallen Kingdom',\n",
    "  'Incredibles 2',\n",
    "  'Aquaman',\n",
    "  'Bohemian Rhapsody',\n",
    "  'Venom',\n",
    "  'Mission: Impossible - Fallout',\n",
    "  'Deadpool 2',\n",
    "  'Fantastic Beasts: The Crimes of Grindelwald'],\n",
    " 2019: ['Avengers: Endgame',\n",
    "  'The Lion King',\n",
    "  'Frozen II',\n",
    "  'Spider-Man: Far from Home',\n",
    "  'Captain Marvel',\n",
    "  'Joker',\n",
    "  'Star Wars: Episode IX - The Rise of Skywalker',\n",
    "  'Toy Story 4',\n",
    "  'Aladdin',\n",
    "  'Jumanji: The Next Level'],\n",
    " 2020: ['Bad Boys for Life',\n",
    "  'Sonic the Hedgehog',\n",
    "  'Ba Bai',\n",
    "  'Dolittle',\n",
    "  'Birds of Prey: And the Fantabulous Emancipation of One Harley Quinn',\n",
    "  'Onward',\n",
    "  'The Invisible Man',\n",
    "  'The Call of the Wild',\n",
    "  'Tenet',\n",
    "  'Tolo Tolo']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "igErAMbIGD5e"
   },
   "outputs": [],
   "source": [
    "with open('./drive/MyDrive/most_successful_movies.pickle', 'rb') as f:  \n",
    "  most_successful_movies = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-X_14WN7BPLA"
   },
   "source": [
    "Final step before filtering the quotes: It turns out that people tend not to use the actual full title when talking about a movie (e.g. people would rather refer to 'the new Star Wars' or 'The Rise of Skywalker' than 'Star Wars: Episode IX - The Rise of Skywalker'). Therefore, we split the movie title into multiple subparts (basically after ':' and ' - ', with the excemption that splitting 'Mission: Impossible' into 'Mission' and 'Impossible' is a terrible idea as basically any politician in the world loves to stress the importance of his or her 'Mission', which leads to many unrelated quotes). So, for 'Mission: Impossible', we make an excemption and only split on 'Mission: Impossible' and the respective title of the movie. \n",
    "As we could see in the analysis of the box office data, many movies are released in the december of a year (especially Star Wars), hence, we decided to filter the quotes of year X by movies released in year X and X-1, to also be able to determine the reactions about a movie some weeks or months after release."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uN0PtnDW8iAS",
    "outputId": "b9d4aaec-b73e-4a13-c0ce-339762fe02e5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('Bad Boys for Life', ['Bad Boys for Life']), ('Sonic the Hedgehog', ['Sonic the Hedgehog']), ('Ba Bai', ['Ba Bai']), ('Dolittle', ['Dolittle']), ('Birds of Prey: And the Fantabulous Emancipation of One Harley Quinn', ['Birds of Prey', 'And the Fantabulous Emancipation of One Harley Quinn']), ('Onward', ['Onward']), ('The Invisible Man', ['The Invisible Man']), ('The Call of the Wild', ['The Call of the Wild']), ('Tenet', ['Tenet']), ('Tolo Tolo', ['Tolo Tolo'])])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year = 2015\n",
    "movies = most_successful_movies[year]\n",
    "movies_dict = {key: [x.strip() for x in re.split(':| - ', key)] for key in movies}\n",
    "if year == 2018:\n",
    "  movies_dict['Mission: Impossible - Fallout'] = ['Mission: Impossible', 'Fallout']\n",
    "elif year == 2015:\n",
    "  movies_dict['Mission: Impossible - Rogue Nation'] = ['Mission: Impossible', 'Rogue Nation']\n",
    "if year != 2015:\n",
    "  year -= 1\n",
    "  movies_dict = movies_dict.update({year: most_successful_movies[year]})\n",
    "  movies_dict = {key: [x.strip() for x in re.split(':| - ', key)] for key in movies}\n",
    "  if year == 2018:\n",
    "    movies_dict['Mission: Impossible - Fallout'] = ['Mission: Impossible', 'Fallout']\n",
    "  year += 1\n",
    "movies_dict.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "_azGKKXJ8_nd"
   },
   "outputs": [],
   "source": [
    "def filter_quotes(path_to_file, path_to_out, movies_dict):\n",
    "  i = 0\n",
    "  with bz2.open(path_to_file, 'rb') as s_file:\n",
    "      try:\n",
    "        os.remove(path_to_out)\n",
    "      except:\n",
    "        pass\n",
    "      with bz2.open(path_to_out, 'wb') as d_file:\n",
    "          for instance in s_file:\n",
    "            i += 1\n",
    "            if i % 100000 == 0:\n",
    "              print(i)\n",
    "            instance = json.loads(instance) # loading a sample\n",
    "            quotation = instance['quotation'] # load quotation\n",
    "            add_quote = False\n",
    "            for movie, words in movies_dict.items():\n",
    "              for word in words:\n",
    "                if word in quotation:\n",
    "                  instance['movie'] = movie\n",
    "                  add_quote = True\n",
    "                  break\n",
    "            if add_quote:\n",
    "              d_file.write((json.dumps(instance)+'\\n').encode('utf-8')) # writing in the new file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B8JpOzxY9ZEJ",
    "outputId": "cea774c1-df36-4633-af09-94ec1d47fcc1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "1300000\n",
      "1400000\n",
      "1500000\n",
      "1600000\n",
      "1700000\n",
      "1800000\n",
      "1900000\n",
      "2000000\n",
      "2100000\n",
      "2200000\n",
      "2300000\n",
      "2400000\n",
      "2500000\n",
      "2600000\n",
      "2700000\n",
      "2800000\n",
      "2900000\n",
      "3000000\n",
      "3100000\n",
      "3200000\n",
      "3300000\n",
      "3400000\n",
      "3500000\n",
      "3600000\n",
      "3700000\n",
      "3800000\n",
      "3900000\n",
      "4000000\n",
      "4100000\n",
      "4200000\n",
      "4300000\n",
      "4400000\n",
      "4500000\n",
      "4600000\n",
      "4700000\n",
      "4800000\n",
      "4900000\n",
      "5000000\n",
      "5100000\n",
      "5200000\n",
      "5300000\n",
      "5400000\n",
      "5500000\n",
      "5600000\n",
      "5700000\n",
      "5800000\n",
      "5900000\n",
      "6000000\n",
      "6100000\n",
      "6200000\n",
      "6300000\n",
      "6400000\n",
      "6500000\n",
      "6600000\n",
      "6700000\n",
      "6800000\n",
      "6900000\n",
      "7000000\n",
      "7100000\n",
      "7200000\n",
      "7300000\n",
      "7400000\n",
      "7500000\n",
      "7600000\n",
      "7700000\n",
      "7800000\n",
      "7900000\n",
      "8000000\n",
      "8100000\n",
      "8200000\n",
      "8300000\n",
      "8400000\n",
      "8500000\n",
      "8600000\n",
      "8700000\n",
      "8800000\n",
      "8900000\n",
      "9000000\n",
      "9100000\n",
      "9200000\n",
      "9300000\n",
      "9400000\n",
      "9500000\n",
      "9600000\n",
      "9700000\n",
      "9800000\n",
      "9900000\n",
      "10000000\n",
      "10100000\n",
      "10200000\n",
      "10300000\n",
      "10400000\n",
      "10500000\n",
      "10600000\n",
      "10700000\n",
      "10800000\n",
      "10900000\n",
      "11000000\n",
      "11100000\n",
      "11200000\n",
      "11300000\n",
      "11400000\n",
      "11500000\n",
      "11600000\n",
      "11700000\n",
      "11800000\n",
      "11900000\n",
      "12000000\n",
      "12100000\n",
      "12200000\n",
      "12300000\n",
      "12400000\n",
      "12500000\n",
      "12600000\n",
      "12700000\n",
      "12800000\n",
      "12900000\n",
      "13000000\n",
      "13100000\n",
      "13200000\n",
      "13300000\n",
      "13400000\n",
      "13500000\n",
      "13600000\n",
      "13700000\n",
      "13800000\n",
      "13900000\n",
      "14000000\n",
      "14100000\n",
      "14200000\n",
      "14300000\n",
      "14400000\n",
      "14500000\n",
      "14600000\n",
      "14700000\n",
      "14800000\n",
      "14900000\n",
      "15000000\n",
      "15100000\n",
      "15200000\n",
      "15300000\n",
      "15400000\n",
      "15500000\n",
      "15600000\n",
      "15700000\n",
      "15800000\n",
      "15900000\n",
      "16000000\n",
      "16100000\n",
      "16200000\n",
      "16300000\n",
      "16400000\n",
      "16500000\n",
      "16600000\n",
      "16700000\n",
      "16800000\n",
      "16900000\n",
      "17000000\n",
      "17100000\n",
      "17200000\n",
      "17300000\n",
      "17400000\n",
      "17500000\n",
      "17600000\n",
      "17700000\n",
      "17800000\n",
      "17900000\n",
      "18000000\n",
      "18100000\n",
      "18200000\n",
      "18300000\n",
      "18400000\n",
      "18500000\n",
      "18600000\n",
      "18700000\n",
      "18800000\n",
      "18900000\n",
      "19000000\n",
      "19100000\n",
      "19200000\n",
      "19300000\n",
      "19400000\n",
      "19500000\n",
      "19600000\n",
      "19700000\n",
      "19800000\n",
      "19900000\n",
      "20000000\n",
      "20100000\n",
      "20200000\n",
      "20300000\n",
      "20400000\n",
      "20500000\n",
      "20600000\n",
      "20700000\n",
      "20800000\n",
      "20900000\n",
      "21000000\n",
      "21100000\n",
      "21200000\n",
      "21300000\n",
      "21400000\n",
      "21500000\n",
      "21600000\n",
      "21700000\n"
     ]
    }
   ],
   "source": [
    "path_to_file = '/content/drive/MyDrive/Quotebank/quotes-{}.json.bz2'.format(year) \n",
    "path_to_out = '/content/drive/MyDrive/quotes-{}-movies.json.bz2'.format(year)\n",
    "\n",
    "filter_quotes(path_to_file, path_to_out, movies_dict)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "filter_quotes.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
