{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fccfb694",
   "metadata": {},
   "source": [
    "### Web Scraping Box Office Mojo Movies\n",
    "This file is a script that webscrapes information about daily box office (in the US) on a movie of choice.\n",
    "\n",
    "We start by importing all needed packages. (Write \"!pip install <package>\" to install missing packages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e877bae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup as BS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44af3d7",
   "metadata": {},
   "source": [
    "We then get the website we are looking for.\n",
    "\n",
    "Change the url to the url of the movie's daily box office. This one is for \"Star Wars IX: The Rise of Skywalker\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6d25460",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.boxofficemojo.com/release/rl3305145857/?ref_=bo_gr_rls\" #Star wars 9\n",
    "#url = 'https://www.boxofficemojo.com/release/rl1442940417/' #Tenet\n",
    "page = requests.get(url)\n",
    "soup = BS(page.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9420f640",
   "metadata": {},
   "source": [
    "To view each data point and their describtion, see the link you are webscraping from.\n",
    "\n",
    "Use BeautifulSoup to get all interesting data and the movie title for file naming:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28d99bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_title = soup.find_all('title')\n",
    "movie_title = movie_title[0].string\n",
    "\n",
    "days = soup.find_all('td', class_='a-text-left mojo-header-column mojo-truncate mojo-field-type-date_interval mojo-sort-column')\n",
    "dow = soup.find_all('td', class_='a-text-left mojo-field-type-date_interval')\n",
    "rank = soup.find_all('td', class_='a-text-right mojo-field-type-rank')\n",
    "daily = soup.find_all('td', class_='a-text-right mojo-field-type-money mojo-estimatable')\n",
    "theaters = soup.find_all('td', class_='a-text-right mojo-field-type-positive_integer mojo-estimatable')\n",
    "\n",
    "#For some weird reason everything involved with money has the same class\n",
    "#So I keep only the ones divisible by 3, because each day has three money classes\n",
    "daily=daily[::3]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2826aa2",
   "metadata": {},
   "source": [
    "Save all data points in arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee5f2758",
   "metadata": {},
   "outputs": [],
   "source": [
    "days_str = []\n",
    "special_events = np.empty(len(days), dtype='<U40')\n",
    "days_ar = []\n",
    "dow_ar = []\n",
    "rank_ar = []\n",
    "daily_ar = []\n",
    "theaters_ar = []\n",
    "\n",
    "for i in range(len(days)):\n",
    "    \n",
    "    #We need the date (days) in the format yyyy-mm-dd\n",
    "    #Luckily we found this information in the \"href\" (the link that the day is connected to)\n",
    "    #Now we extract it along with everything else\n",
    "    days_ar.append(str(days[i].select('a'))) \n",
    "    days_ar[i] = days_ar[i][days_ar[i].find('2'):]\n",
    "    days_ar[i] = days_ar[i][:days_ar[i].find('/')]\n",
    "    \n",
    "    #Assign special events to dates (such as christmas day or covid-19 pandemic, might be interesting)\n",
    "    if days[i].select('span') != []:\n",
    "        special_events[i] = days[i].select('span')[0].string\n",
    "        #OOOPS. Sometimes there might be two special events (covid and christmas)... This is my attempt to take care of it\n",
    "        if days[i].select('span')[0].string == None:\n",
    "            first_event = str(days[i].select('span'))\n",
    "            first_event = first_event[first_event.find('>'):]\n",
    "            second_event = first_event[first_event.find('/'):]\n",
    "            second_event = second_event[:second_event.find('<')]\n",
    "            second_event = second_event.replace('/','')\n",
    "            second_event = second_event.replace('>','')\n",
    "            first_event = first_event[:first_event.find('<')]\n",
    "            first_event = first_event.replace('>','')\n",
    "            special_events[i] = first_event+\"-\"+second_event\n",
    "            \n",
    "    else:\n",
    "        special_events[i] = np.NaN\n",
    "    \n",
    "    #Get the rest of the data as strings\n",
    "    dow_ar.append(dow[i].select('a')[0].string)\n",
    "    rank_ar.append(rank[i].string)\n",
    "    daily_ar.append(daily[i].string)\n",
    "    theaters_ar.append(theaters[i].string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9aa4dc4",
   "metadata": {},
   "source": [
    "Make a pandas dataframe with all of the arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa5091ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_df = pd.DataFrame({'days': days_ar, 'dow': dow_ar, 'rank':rank_ar, 'daily': daily_ar, 'theaters': theaters_ar, 'special events': special_events})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d73db2e",
   "metadata": {},
   "source": [
    "All of the data points are strings, but we would like a float format so that we can do computations later.\n",
    "\n",
    "We remove all commas and dollar-signs in order to convert strings to floats using the function below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fade0375",
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_str_to_float(column):\n",
    "    float_column = np.empty(len(column), dtype='<U10')\n",
    "    for i in range(len(column)):\n",
    "        float_column[i] = column[i].replace(',','')\n",
    "        if '$' in column[i]:\n",
    "            float_column[i] = float(float_column[i].replace('$',''))\n",
    "    return float_column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8dd15a",
   "metadata": {},
   "source": [
    "Now we filter the columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc6ab3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_df['daily'] = from_str_to_float(movie_df['daily'])\n",
    "movie_df['rank'] = from_str_to_float(movie_df['rank'])\n",
    "movie_df['theaters'] = from_str_to_float(movie_df['theaters'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975a1a2c",
   "metadata": {},
   "source": [
    "Now we want to save our data frame to a csv file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96c2d5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Because spaces are a no-go in file names\n",
    "root = 'time_series_box_office_data'\n",
    "movie_title = movie_title.replace(\" \", \"_\")\n",
    "movie_title = movie_title.replace(\"-\", \"_\")\n",
    "movie_title = movie_title.replace(\":\", \"\")\n",
    "\n",
    "movie_df.to_csv(root+\"/\"+movie_title+\".csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
